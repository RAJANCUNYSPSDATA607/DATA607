---
title: "Data607_Project4_Rajan"
author: "Krishna Rajan"
date: "4/15/2018"
output:
  pdf_document: default
  html_document: default
  word_document: default
---
```{r}
##PROJECT 4: Document Classification
##It can be useful to be able to classify new "test" documents using already classified "training" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  For this project, you can start with a spam/ham dataset, then predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).   One example corpus:  https://spamassassin.apache.org/publiccorpus/

##Install Tools
require(stringr)
require(tm)
require(RTextTools) 
require(SnowballC)
require(knitr)
require(ggplot2)
require(dplyr)

##the following functions are helpful to wrap the functions together
toVCorpus <- function(file_path) {
  corpus <- file_path %>%                            
    paste(., list.files(.), sep = "/") %>%          # Create a vector of file paths 
    lapply(readLines) %>%                           # Read the text in each file
    VectorSource() %>%                              # Turn into VectorSource
    VCorpus()                                       # Turn into VCorpus
  return(corpus)
}
docClean <- function(corpus) {
  corpus <- corpus %>%
    tm_map(removeNumbers) %>%                               # Remove numbers
    tm_map(str_replace_all, "[[:punct:]]", " ") %>% # Remove punctuations 
    tm_map(tolower) %>%                                       # Remove upper cases
    tm_map(PlainTextDocument) %>%                           # Transform back to PlainTextDocument
    tm_map(removeWords, stopwords("en")) %>%        # Remove stop words
    tm_map(stemDocument)                                      # Reduce to stems
  return(corpus)
}
addTag <- function(corpus, tag, value){
  for (i in 1:length(corpus)){
    meta(corpus[[i]], tag) <- value                    # Add the value to the specified tag
  }
  return(corpus)
}

##File Path for HAM & SPAM files
ham_paths <- "/Users/rajans/Desktop/CUNY/Data Acquition & Management/Project 4/HAM"
spam_paths <- "/Users/rajans/Desktop/CUNY/Data Acquition & Management/Project 4/SPAM"

# Create ham corpus
ham_corpus <- ham_paths %>%
  toVCorpus %>%
  docClean %>%
  addTag(tag = "ham_spam", value = "ham")

# Create spam corpus
spam_corpus <- spam_paths %>%
  toVCorpus %>%
  docClean %>%
  addTag(tag = "ham_spam", value = "spam")


spamassassin_corpus <- c(ham_corpus, spam_corpus)

spamassassin_corpus <- spamassassin_corpus[sample(c(1:length(spamassassin_corpus)))]

# Check ham/spam proportion
spamassassin_corpus_prop <- spamassassin_corpus %>%
  meta(tag = "ham_spam") %>%
  unlist() %>%
  table() 
spamassassin_corpus_prop

spamassassin_dtm <- spamassassin_corpus %>% 
  DocumentTermMatrix() %>% 
  removeSparseTerms(1-(10/length(spamassassin_corpus)))
spamassassin_labels <- unlist(meta(spamassassin_corpus, "ham_spam"))

##N <- length(spamassassin_labels)
##split <- round(0.8*N) 
##container <- create_container(spamassassin_dtm, labels = spamassassin_labels,trainSize = 1:split,
##testSize = (split+1):N,
##virgin = FALSE
##)
## unfortunately I am struck here as I am not able to create a container (getting an error message) and I need to stop the process here.

##Training the Module
##svm_model_spamassassin <- train_model(container, "SVM")
##tree_model_spamassassin <- train_model(container, "TREE")
##maxent_model_spamassassin <- train_model(container, "MAXENT") 
```


